{"experiments_dir": "/data/sheng/e2e/e2e-nlg-challenge-2017/experiments", "log_level": "INFO", "random_seed": 1, "mode": "train", "model_fn": null, "data-module": "components.data.e2e_data_MLP", "model-module": "components.model.e2e_model_MLP", "training-module": "components.trainer.e2e_trainer_MLP", "evaluation-module": "components.evaluator.e2e_evaluator", "data_params": {"train_data": "/data/sheng/e2e/data/trainset.csv", "dev_data": "/data/sheng/e2e/data/devset.csv", "test_data": null, "max_src_len": 50, "max_tgt_len": 50}, "model_params": {"embedding_dim": 256, "embedding_dropout": 0.1, "teacher_forcing_ratio": 1.0, "encoder_params": {"input_size": 256, "hidden_size": 512, "dropout": 0.0}, "decoder_params": {"input_size": 512, "hidden_size": 512, "dropout": 0.0}}, "training_params": {"evaluate_prediction": true, "save_model_each_epoch": true, "n_epochs": 30, "batch_size": 16, "optimizer": "SGD", "learning_rate": 0.1, "modeltype": "e2e_model_MLP", "model_dir": "/data/sheng/e2e/e2e-nlg-challenge-2017/experiments/e2e_model_MLP_seed1-emb256-hid512-drop0.0-bs16-lr0.1_2018-Oct-12_15:41:33"}}